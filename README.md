Description
===========

There is a server log with following format (note the double quotes around <OutputErrorInfo>):

	<ClientIP> <RequestDate> <RequestMethod> <OutputStatusCode> “<OutputErrorInfo>”

	<OutputStatusCode> == 200 implies request ended in no error
	<OutputStatusCode> != 200 implies request ended in error and the error message is in 	<OutputErrorInfo> 

Write a script that helps answer the following questions:

1. How many requests completed with and without errors ?
2. What are top 5 most common error messages ?
3. How would your solution be to collect these answers from 10 servers ?

Here is the directory structure for this project:

	log-parser/
	|--- README.md
	|--- bin
	│   |--- log-analyzer.py
	│   \-- log-generator.py
	|--- hosts.txt
	\-- logs
	    |--- 10.21.43.10.log
	    |--- 10.21.43.105.log
	    |--- 10.21.43.14.log
	    |--- 10.21.43.140.log
	    |--- 10.21.43.148.log
	    |--- 10.21.43.160.log
	    |--- 10.21.43.163.log
	    |--- 10.21.43.179.log
	    |--- 10.21.43.191.log
	    |--- 10.21.43.21.log
	    |--- 10.21.43.25.log
	    \-- test.log

Scripts
=======

## log-generator

This is a very quick model generator for the purpose of this demo. The script generates a log file of 800 - 5000 lines, with a random distribution of response codes, and appropriate error messages.

Based on the model the following will be true:

1. The following error codes could be randomly generated: '200', '302', '400', '401', '404', '415', '500'
2. Before generating a random code, each code is given a random weight, and thus chance that it could be generated within run. This number is actually printed as a comment at the top of every log file (for dubugging purposes)
3. Given a code, generate a random method: GET, POST, PUT, DELETE
4. Given a code and a method, generate a random message

## log-analyzer

	$ ./log-analyzer.py -h
	usage: log-analyzer.py [-h] [-s SERVER] [-f LOG_FILE] [-j] [-v] [-d]
	                       [--remote]

	Log analyzer tool that scans and provides statistics around the errors that
	occurred in a log

	optional arguments:
	  -h, --help     show this help message and exit
	  -s SERVER      A file containing a list of servers to connect to
	  -f LOG_FILE    A local log file to analyze
	  -j, --json     Enables printing out as json
	  -v, --verbose  Turns on verbose output
	  -d, --debug    Turns on debug output
	  --remote       Only when this is specified will it go out and walk through
	                 scan the logs across the specified list of host, aggregrate
	                 the results, and provide an aggregated report. Otherwise, A
	                 local log file must be specified

    
Questions
=========

## Problem 1 & 2: How many requests completed with and without errors? What are top 5 most common error messages?

For the `test.log` that I generated and ran the `log-analyser.py` script against, there was a stated 64% chance that I would generate a success; the actual based on the success and failure count was 46%. Unfortunately, that is of course much higher than I would have liked, but does not affect the purposes of the demo.

What we can see below is that 57% of all the errors came from `Unauthorized`. Based on this information, I also generated some additional statistics on the distribution of this error being generated by their respective methods.

	$ cd log-parser/bin/
	$ ./log-analyzer.py -f ../logs/test.log
    Summary
    ======
    
      Total Successes: 2701
      Total Failures: 1470
    
    The TOP 5 Errors
    ==================
    1. Unauthorized (57.89% - 851 errors)
      - 35.49% PUT
      - 31.96% GET
      - 32.55% DELETE
    2. Account does not exist (7.28% - 107 errors)
      - 23.36% PUT
      - 60.75% POST
      - 6.54% DELETE
      - 9.35% GET
    3. Invalid user/password credentials (6.39% - 94 errors)
      - 31.91% PUT
      - 68.09% POST
    4. Unknown server error (5.58% - 82 errors)
      - 4.88% PUT
      - 8.54% POST
      - 42.68% GET
      - 43.90% DELETE
    5. Missing Account ID (4.90% - 72 errors)
      - 50.00% PUT
      - 50.00% GET

## Problem 3: How would your solution be to collect these answers from 10 servers ?

There were two solutions I could think of:

1. I could write a tool that would remotely scan a log file, and generate the stats locally.
2. (i) I leverage the existing script; (ii) have this be installed on remote machines (e.g. via puppet); (iii) perform the same local stats as above; (iv) and finally write a wrapper logic that walks through all these hosts, executing the local `log-analyzer.py`, and aggregating the results across the cluster.

In my first few minutes of researching, I had written a python log parser exactly 2-years-ago that walked a list of servers and scanned through a set of log file in a given directory:

    https://github.com/gradeawarrior/python-log-parser

The concern I had with this approach is that I would incur some loss of speed and efficiency by having to effectively transfer the file over-the-wire. This could be a big problem for  large log files. In other words, network latency could be a big problem.

The latter offered better efficiency, and the issue of deployment of this script across multiple hosts is solvable by usage of Ops tooling such as puppet. Another problem I faced was to serialize the local log statistics; this was solved by serializing the existing data-structure to JSON.

Based on a fictional set of hosts, here is what the remote operation might look like:

    $ ssh psalas@10.21.43.10 ./log-parser.py -f server.log --json
    $ ssh psalas@10.21.43.105 ./log-parser.py -f server.log --json
    $ ssh psalas@10.21.43.14 ./log-parser.py -f server.log --json
    $ ssh psalas@10.21.43.140 ./log-parser.py -f server.log --json
    $ ssh psalas@10.21.43.148 ./log-parser.py -f server.log --json
    $ ssh psalas@10.21.43.160 ./log-parser.py -f server.log --json
    $ ssh psalas@10.21.43.163 ./log-parser.py -f server.log --json
    $ ssh psalas@10.21.43.179 ./log-parser.py -f server.log --json
    $ ssh psalas@10.21.43.191 ./log-parser.py -f server.log --json
    $ ssh psalas@10.21.43.21 ./log-parser.py -f server.log --json
    $ ssh psalas@10.21.43.25 ./log-parser.py -f server.log --json

Then after aggregating the results, here is what the results would look like:

	$ cd log-parser/bin/
    $ ./log-analyzer.py -s ../hosts.txt --remote
    ------ psalas@10.21.43.10 ------
    ------ psalas@10.21.43.105 ------
    ------ psalas@10.21.43.14 ------
    ------ psalas@10.21.43.140 ------
    ------ psalas@10.21.43.148 ------
    ------ psalas@10.21.43.160 ------
    ------ psalas@10.21.43.163 ------
    ------ psalas@10.21.43.179 ------
    ------ psalas@10.21.43.191 ------
    ------ psalas@10.21.43.21 ------
    ------ psalas@10.21.43.25 ------
    Summary
    ======
    
      Total Successes: 25603
      Total Failures: 5377
    
    The TOP 5 Errors
    ==================
    1. Unauthorized (19.92% - 1071 errors)
    2. Account does not exist (16.76% - 901 errors)
    3. Invalid user/password credentials (13.67% - 735 errors)
    4. Missing Transaction ID (9.62% - 517 errors)
    5. Invalid JSON (9.09% - 489 errors)

## Problem 4: What were all the errors from all servers?

The following are all the errors in all logs (in this demo):

    $ ./log-analyzer.py -s ../hosts.txt --remote -v

1. Unauthorized (19.92% - 1071 errors)
2. Account does not exist (16.76% - 901 errors)
3. Invalid user/password credentials (13.67% - 735 errors)
4. Missing Transaction ID (9.62% - 517 errors)
5. Invalid JSON (9.09% - 489 errors)
6. Missing Account ID (8.57% - 461 errors)
7. Unknown server error (5.28% - 284 errors)
8. Account balance too low (4.82% - 259 errors)
9. Method not allowed (2.77% - 149 errors)
10. Transaction does not exist (2.06% - 111 errors)
11. Redirect (1.58% - 85 errors)
12. Not Found (1.58% - 85 errors)
13. Object not found (1.25% - 67 errors)
14. Nullpointer Exception (1.04% - 56 errors)
15. Cannot convert Boolean to Integer (0.56% - 30 errors)
16. Illegal Division by zero (0.52% - 28 errors)
17. Malformed JSON (0.50% - 27 errors)
18. Cannot convert String to Integer (0.41% - 22 errors)

